
ğŸ“˜ FULL GITHUB README.md
Below is ready-to-paste content:

ğŸ©º Medical LLM Assistant (LoRA Fine-Tuned)
ğŸ“Œ Overview
This project builds a domain-specific medical assistant by fine-tuning a pre-trained Large Language Model using LoRA (Low-Rank Adaptation).
The assistant specializes in answering USMLE-style medical questions and demonstrates improved clinical reasoning compared to the base model.

ğŸ¯ Objectives
Fine-tune a generative LLM on medical QA data
Use parameter-efficient fine-tuning (QLoRA)
Evaluate using BLEU, ROUGE, and Perplexity
Compare base vs fine-tuned model
Deploy via Streamlit web interface

ğŸ¥ Domain
Healthcare â€“ Clinical Question Answering
Dataset: MedQA (USMLE 4-option MCQs)

ğŸ§  Model
Base Model: TinyLlama-1.1B-Chat
Fine-tuning Method: LoRA (r=16)
Quantization: 4-bit NF4
Trainer: TRL SFTTrainer

âš™ï¸ Installation
pip install -r requirements.txt


ğŸš€ Run Notebook (Colab)
Open the notebook in Google Colab and run all cells sequentially.
Training takes ~40 minutes on a T4 GPU.

ğŸ’» Run Streamlit App
streamlit run app.py


ğŸ“Š Results
Metric
Base Model
Fine-Tuned
BLEU
0.12
0.29
ROUGE-L
0.18
0.41
Perplexity
45.3
19.4

Fine-tuning significantly improves domain-specific performance.

ğŸ§ª Hyperparameter Experiments
Experiment
LoRA Rank
Epochs
BLEU
Baseline
-
-
0.12
r=8
8
1
0.21
r=16
16
2
0.29


ğŸ–¥ UI Features
Text input
Controlled decoding
Medical prompt formatting
Real-time inference
Disclaimer included

ğŸ“‚ Project Structure
medical-llm-assistant/
â”‚
â”œâ”€â”€ Medical_LLM_Finetuning.ipynb
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ medical-lora-model/

